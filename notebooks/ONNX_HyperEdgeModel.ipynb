{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938ae320-3a72-4cdc-9974-a8d2de52b0b0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'onnx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnx'"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip install onnx onnxruntime onnxscript torch torch_geometric \n",
    "pip install torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.2.0+cpu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11523cfd-a118-4ea3-afc8-afdbd80b8e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch version: 2.6.0\n",
      "torch-scatter version: 2.1.2\n",
      "ONNX version: 1.17.0\n",
      "onnxruntime version: 1.20.1\n",
      "torch_geometric version: 2.6.1\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils import scatter\n",
    "import torch_geometric\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_scatter import scatter_add\n",
    "from typing import Optional, Dict\n",
    "import torch_scatter\n",
    "\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import onnxscript\n",
    "from onnxscript import opset18  # opset 18 is the latest (and only) supported version for now\n",
    "\n",
    "print(\"Torch version:\", torch.__version__)\n",
    "print(\"torch-scatter version:\", torch_scatter.__version__)\n",
    "print(\"ONNX version:\", onnx.__version__)\n",
    "print(\"onnxruntime version:\", ort.__version__)\n",
    "print(\"torch_geometric version:\", torch_geometric.__version__)\n",
    "\n",
    "torch.random.manual_seed(42);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "075165c4-756a-4fcc-a7c5-19493e827ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/xju/miniconda3/envs/jupyterbook/lib/python3.12/site-packages/torch/onnx/_internal/_exporter_legacy.py:101: UserWarning: torch.onnx.dynamo_export only implements opset version 18 for now. If you need to use a different opset version, please register them with register_custom_op.\n",
      "  warnings.warn(\n",
      "/Users/xju/miniconda3/envs/jupyterbook/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.Op.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n",
      "/Users/xju/miniconda3/envs/jupyterbook/lib/python3.12/site-packages/onnxscript/converter.py:823: FutureWarning: 'onnxscript.values.OnnxFunction.param_schemas' is deprecated in version 0.1 and will be removed in the future. Please use '.op_signature' instead.\n",
      "  param_schemas = callee.param_schemas()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aten::gelu.default is supported by ONNX registry:     True\n"
     ]
    }
   ],
   "source": [
    "onnx_registry = torch.onnx.OnnxRegistry()\n",
    "print(f\"aten::gelu.default is supported by ONNX registry: \\\n",
    "    {onnx_registry.is_registered_op(namespace='aten', op_name='gelu', overload='default')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3df4a724-6d48-47a7-9571-8289da3c7286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge features shape: torch.Size([2000, 10])\n"
     ]
    }
   ],
   "source": [
    "num_spacepoints = 100\n",
    "spacepoint_features = 3\n",
    "num_edges = 2000\n",
    "\n",
    "x = torch.rand(num_spacepoints, spacepoint_features).to(torch.float32)\n",
    "edge_list = torch.randint(0, 100, (2, num_edges)).to(torch.int64)\n",
    "row, col = edge_list\n",
    "\n",
    "num_edge_features = 4\n",
    "edge_attr = torch.rand(num_edges, num_edge_features).to(torch.float32)\n",
    "\n",
    "out = torch.cat([x[row], x[col], edge_attr], 1).float()\n",
    "print(\"edge features shape:\", out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06738e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "x2 = torch.rand(num_spacepoints, spacepoint_features).to(torch.float32)\n",
    "edge_list2 = torch.randint(0, 100, (2, num_edges)).to(torch.int64)\n",
    "row2, col2 = edge_list2\n",
    "edge_attr2 = torch.rand(num_edges, num_edge_features).to(torch.float32)\n",
    "out2 = torch.cat([x2[row2], x2[col2], edge_attr2], 1).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02a863a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg mean: torch.Size([100, 10]) tensor([0.5400, 0.4889, 0.4279])\n",
      "agg sum: torch.Size([100, 10]) tensor([11.3401, 10.2661,  8.9863])\n",
      "agg max: torch.Size([100, 10]) tensor([0.9344, 0.9712, 0.9005])\n"
     ]
    }
   ],
   "source": [
    "agg_mean = scatter(out, col, dim=0, dim_size=x.size(0), reduce='mean')\n",
    "agg_sum = scatter(out, col, dim=0, dim_size=x.size(0), reduce='sum')\n",
    "agg_max = scatter(out, col, dim=0, dim_size=x.size(0), reduce='max')\n",
    "print(\"agg mean:\", agg_mean.shape, agg_mean[0, :3])\n",
    "print(\"agg sum:\", agg_sum.shape, agg_sum[0, :3])\n",
    "print(\"agg max:\", agg_max.shape, agg_max[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "692aff1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg sum2: torch.Size([100, 10]) tensor([11.3401, 10.2661,  8.9863])\n"
     ]
    }
   ],
   "source": [
    "agg_sum2 = torch.scatter_add(torch.zeros(x.size(0), out.size(1)), 0, col.unsqueeze(1).expand(-1, out.size(1)), out)\n",
    "print(\"agg sum2:\", agg_sum2.shape, agg_sum2[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "420cf221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scatter:  torch.Size([100, 10]) tensor([11.3401, 10.2661,  8.9863])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/838719481.py:1: UserWarning: The reduce argument of torch.scatter with Tensor src is deprecated and will be removed in a future PyTorch release. Use torch.scatter_reduce instead for more reduction options. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/aten/src/ATen/native/TensorAdvancedIndexing.cpp:234.)\n",
      "  agg_scatter = torch.scatter(torch.zeros(x.size(0), out.size(1)), 0, col.unsqueeze(1).expand(-1, out.size(1)), out, reduce=\"add\")\n"
     ]
    }
   ],
   "source": [
    "agg_scatter = torch.scatter(torch.zeros(x.size(0), out.size(1)), 0, col.unsqueeze(1).expand(-1, out.size(1)), out, reduce=\"add\")\n",
    "print(\"scatter: \", agg_scatter.shape, agg_scatter[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "164e4e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agg mean3: torch.Size([100, 10]) tensor([0.5400, 0.4889, 0.4279])\n",
      "agg sum3: torch.Size([100, 10]) tensor([11.3401, 10.2661,  8.9863])\n",
      "agg max3: torch.Size([100, 10]) tensor([0.9344, 0.9712, 0.9005])\n"
     ]
    }
   ],
   "source": [
    "index = col.unsqueeze(1).expand(-1, out.size(1))\n",
    "agg_mean3 = torch.scatter_reduce(torch.zeros(x.size(0), out.size(1)), 0, index=index, src=out, reduce=\"mean\", include_self=False)\n",
    "agg_sum3 = torch.scatter_reduce(torch.zeros(x.size(0), out.size(1)), 0, index=index, src=out, reduce=\"sum\")\n",
    "agg_max3 = torch.scatter_reduce(torch.zeros(x.size(0), out.size(1)), 0, index=index, src=out, reduce=\"amax\")\n",
    "print(\"agg mean3:\", agg_mean3.shape, agg_mean3[0, :3])\n",
    "print(\"agg sum3:\", agg_sum3.shape, agg_sum3[0, :3])\n",
    "print(\"agg max3:\", agg_max3.shape, agg_max3[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed28da66",
   "metadata": {},
   "outputs": [],
   "source": [
    "tolerance = 1e-5\n",
    "assert torch.allclose(agg_mean, agg_mean3, atol=tolerance)\n",
    "assert torch.allclose(agg_sum, agg_sum3, atol=tolerance)\n",
    "assert torch.allclose(agg_max, agg_max3, atol=tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ea516144",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelPyGScatter(torch.nn.Module):\n",
    "    def forward(self, index: torch.Tensor, src: torch.Tensor, size: int, reduce: str) -> torch.Tensor:\n",
    "        return scatter(src, index, dim=0, dim_size=size, reduce=reduce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8ee1fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 11:14:23.251000 72441 site-packages/torch/onnx/_internal/exporter/_registration.py:66] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ModelPyGScatter()` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ModelPyGScatter()` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'pkg.onnxscript.torch_lib.common': 1, '': 18, 'pkg.onnxscript.torch_lib': 1},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.6.0',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"index\"<INT64,[2000]>,\n",
       "                %\"src\"<FLOAT,[2000,10]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"div\"<FLOAT,[100,10]>\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Constant_0\n",
       "                  %\"val_0\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[1]>(array([100]), name=None)}\n",
       "             1 |  # node_ConstantOfShape_1\n",
       "                  %\"val_1\"<?,?> ⬅️ ::ConstantOfShape(%\"val_0\")\n",
       "             2 |  # node_CastLike_2\n",
       "                  %\"new_zeros\"<FLOAT,[100]> ⬅️ ::CastLike(%\"val_1\", %\"src\")\n",
       "             3 |  # node_Constant_3\n",
       "                  %\"val_2\"<?,?> ⬅️ ::Constant() {value_float=1.0}\n",
       "             4 |  # node_Constant_4\n",
       "                  %\"val_3\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[1]>(array([2000]), name=None)}\n",
       "             5 |  # node_Expand_5\n",
       "                  %\"val_4\"<?,?> ⬅️ ::Expand(%\"val_2\", %\"val_3\")\n",
       "             6 |  # node_CastLike_6\n",
       "                  %\"new_ones\"<FLOAT,[2000]> ⬅️ ::CastLike(%\"val_4\", %\"src\")\n",
       "             7 |  # node_aten_scatter_add_7\n",
       "                  %\"scatter_add\"<FLOAT,[100]> ⬅️ pkg.onnxscript.torch_lib::aten_scatter_add(%\"new_zeros\", %\"index\", %\"new_ones\") {dim=0}\n",
       "             8 |  # node_Constant_8\n",
       "                  %\"val_5\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[]>(array(1), name=None)}\n",
       "             9 |  # node_Cast_9\n",
       "                  %\"scalar_tensor_default\"<FLOAT,[]> ⬅️ ::Cast(%\"val_5\") {to=FLOAT}\n",
       "            10 |  # node_Max_10\n",
       "                  %\"clamp\"<FLOAT,[100]> ⬅️ ::Max(%\"scatter_add\", %\"scalar_tensor_default\")\n",
       "            11 |  # node_Constant_11\n",
       "                  %\"val_6\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[2]>(array([-1,  1]), name=None)}\n",
       "            12 |  # node_Cast_12\n",
       "                  %\"val_7\"<?,?> ⬅️ ::Cast(%\"val_6\") {to=INT64}\n",
       "            13 |  # node_Reshape_13\n",
       "                  %\"view\"<INT64,[2000,1]> ⬅️ ::Reshape(%\"index\", %\"val_7\") {allowzero=0}\n",
       "            14 |  # node_Constant_14\n",
       "                  %\"val_8\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[2]>(array([2000,   10]), name=None)}\n",
       "            15 |  # node_aten_expand_15\n",
       "                  %\"expand\"<INT64,[2000,10]> ⬅️ pkg.onnxscript.torch_lib::aten_expand(%\"view\", %\"val_8\")\n",
       "            16 |  # node_Constant_16\n",
       "                  %\"val_9\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[2]>(array([100,  10]), name=None)}\n",
       "            17 |  # node_ConstantOfShape_17\n",
       "                  %\"val_10\"<?,?> ⬅️ ::ConstantOfShape(%\"val_9\")\n",
       "            18 |  # node_CastLike_18\n",
       "                  %\"new_zeros_1\"<FLOAT,[100,10]> ⬅️ ::CastLike(%\"val_10\", %\"src\")\n",
       "            19 |  # node_aten_scatter_add_19\n",
       "                  %\"scatter_add_1\"<FLOAT,[100,10]> ⬅️ pkg.onnxscript.torch_lib::aten_scatter_add(%\"new_zeros_1\", %\"expand\", %\"src\") {dim=0}\n",
       "            20 |  # node_Cast_20\n",
       "                  %\"val_11\"<?,?> ⬅️ ::Cast(%\"val_6\") {to=INT64}\n",
       "            21 |  # node_Reshape_21\n",
       "                  %\"view_1\"<FLOAT,[100,1]> ⬅️ ::Reshape(%\"clamp\", %\"val_11\") {allowzero=0}\n",
       "            22 |  # node_aten_expand_22\n",
       "                  %\"expand_1\"<FLOAT,[100,10]> ⬅️ pkg.onnxscript.torch_lib::aten_expand(%\"view_1\", %\"val_9\")\n",
       "            23 |  # node_aten_div_23\n",
       "                  %\"div\"<FLOAT,[100,10]> ⬅️ pkg.onnxscript.torch_lib::aten_div(%\"scatter_add_1\", %\"expand_1\")\n",
       "            return %\"div\"<FLOAT,[100,10]>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::aten_scatter_add(\n",
       "            inputs=(\n",
       "                %\"self\"<?,?>,\n",
       "                %\"index\"<?,?>,\n",
       "                %\"src\"<?,?>\n",
       "            ),\n",
       "            attributes={\n",
       "                dim: UNDEFINED\n",
       "            }\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"return_val\"<?,?> ⬅️ ::ScatterElements(%\"self\", %\"index\", %\"src\") {axis=RefAttr('axis', INT, ref_attr_name='dim'), reduction=add}\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::aten_expand(\n",
       "            inputs=(\n",
       "                %\"self\"<?,?>,\n",
       "                %\"size\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"size_0\"<?,?> ⬅️ ::Cast(%\"size\") {to=7}\n",
       "            1 |  # n1\n",
       "                 %\"size_1\"<?,?> ⬅️ ::Abs(%\"size_0\")\n",
       "            2 |  # n2\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Expand(%\"self\", %\"size_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::aten_div(\n",
       "            inputs=(\n",
       "                %\"self\"<?,?>,\n",
       "                %\"other\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Div(%\"self\", %\"other\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::Rank(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::IsScalar(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"tmp_0\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            2 |  # n2\n",
       "                 %\"tmp_1\"<?,?> ⬅️ ::Constant() {value_int=0}\n",
       "            3 |  # n3\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Equal(%\"tmp_0\", %\"tmp_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, index: \"i64[2000]\", src: \"f32[2000, 10]\", size, reduce):\n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/1365350551.py:3 in forward, code: return scatter(src, index, dim=0, dim_size=size, reduce=reduce)\n",
       "                    new_zeros: \"f32[100]\" = torch.ops.aten.new_zeros.default(src, [100], pin_memory = False)\n",
       "                    new_ones: \"f32[2000]\" = torch.ops.aten.new_ones.default(src, [2000], pin_memory = False)\n",
       "                    scatter_add: \"f32[100]\" = torch.ops.aten.scatter_add.default(new_zeros, 0, index, new_ones);  new_zeros = new_ones = None\n",
       "                    scalar_tensor_default: \"f32[]\" = torch.ops.aten.scalar_tensor.default(1, dtype = torch.float32)\n",
       "                    clamp: \"f32[100]\" = torch.ops.aten.clamp.Tensor(scatter_add, scalar_tensor_default);  scatter_add = scalar_tensor_default = None\n",
       "                    view: \"i64[2000, 1]\" = torch.ops.aten.view.default(index, [-1, 1]);  index = None\n",
       "                    expand: \"i64[2000, 10]\" = torch.ops.aten.expand.default(view, [2000, 10]);  view = None\n",
       "                    new_zeros_1: \"f32[100, 10]\" = torch.ops.aten.new_zeros.default(src, [100, 10], pin_memory = False)\n",
       "                    scatter_add_1: \"f32[100, 10]\" = torch.ops.aten.scatter_add.default(new_zeros_1, 0, expand, src);  new_zeros_1 = expand = src = None\n",
       "                    view_1: \"f32[100, 1]\" = torch.ops.aten.view.default(clamp, [-1, 1]);  clamp = None\n",
       "                    expand_1: \"f32[100, 10]\" = torch.ops.aten.expand.default(view_1, [100, 10]);  view_1 = None\n",
       "                    div: \"f32[100, 10]\" = torch.ops.aten.div.Tensor(scatter_add_1, expand_1);  scatter_add_1 = expand_1 = None\n",
       "                    return (div,)\n",
       "            \n",
       "        Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='index'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='src'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=ConstantArgument(name='size', value=100), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=ConstantArgument(name='reduce', value='mean'), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='div'), target=None)])\n",
       "        Range constraints: {s0: VR[2, int_oo], s1: VR[2, int_oo]}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelPyGScatter()\n",
    "model.eval()\n",
    "# model = torch.jit.script(model)\n",
    "torch.onnx.export(model, (col, out, x.size(0), \"mean\"), \"pyg_scatter.onnx\", opset_version=18, dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2f6def8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_scatter(onnx_file: str, index, src):\n",
    "    m = onnx.load(onnx_file)\n",
    "    sess = ort.InferenceSession(onnx_file)\n",
    "    print(\"input size: \", len(m.graph.input))\n",
    "    # print(m.graph.input)\n",
    "    inputs = {\n",
    "        m.graph.input[0].name: index.numpy(),\n",
    "        m.graph.input[1].name: src.numpy(),\n",
    "        # m.graph.input[2].name: x.size(0),\n",
    "        # m.graph.input[3].name: reduce\n",
    "    }\n",
    "    return torch.from_numpy(sess.run([m.graph.output[0].name], inputs)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf0c6eb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  2\n",
      "ort_result: torch.Size([100, 10]) tensor([0.5400, 0.4889, 0.4279])\n"
     ]
    }
   ],
   "source": [
    "ort_result = test_scatter(\"pyg_scatter.onnx\", col, out)\n",
    "print(\"ort_result:\", ort_result.shape, ort_result[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6cd00a34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input size:  2\n",
      "ort_result2: torch.Size([100, 10]) tensor([0.5586, 0.4802, 0.4576])\n",
      "agg_mean_v2: torch.Size([100, 10]) tensor([0.5586, 0.4802, 0.4576])\n"
     ]
    }
   ],
   "source": [
    "ort_result2 = test_scatter(\"pyg_scatter.onnx\", col2, out2)\n",
    "agg_mean_v2 = scatter(out2, col2, dim=0, dim_size=x2.size(0), reduce='mean')\n",
    "print(\"ort_result2:\", ort_result2.shape, ort_result2[0, :3])\n",
    "print(\"agg_mean_v2:\", agg_mean_v2.shape, agg_mean_v2[0, :3])\n",
    "assert torch.allclose(agg_mean_v2, ort_result2, atol=tolerance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "fd986026",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModuleHyperEdgeFinding(nn.Module):\n",
    "    def forward(self, x, hyperedge_index, r: int = 2, message_feats: int = 3):\n",
    "        hyperedge_index = hyperedge_index.permute(dims=(1,0))\n",
    "        x_hyper = torch.gather(\n",
    "            x.unsqueeze(1).expand([-1,r,-1]),\n",
    "            0,\n",
    "            hyperedge_index.unsqueeze(2).expand([-1, -1, message_feats])\n",
    "        ).transpose(1,2)\n",
    "        return x_hyper.sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "097e5f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __hyperedge_finding__(x, hyperedge_index, r: int, message_feats: int):\n",
    "    hyperedge_index = hyperedge_index.permute(dims=(1,0))\n",
    "    x_hyper = torch.gather(\n",
    "        x.unsqueeze(1).expand([-1,r,-1]),\n",
    "        0,\n",
    "        hyperedge_index.unsqueeze(2).expand([-1, -1, message_feats])\n",
    "    ).transpose(1,2)\n",
    "    return x_hyper.sum(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0471211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_hperedge_finding(x, hyperedge_index, r: int, message_feats: int):\n",
    "    # Unpack node indices and hyperedge indices\n",
    "    node_idx, hyperedge_idx = hyperedge_index\n",
    "\n",
    "    # Create an output tensor for aggregated hyperedge features\n",
    "    hyperedge_feats = torch.zeros(hyperedge_idx.max() + 1, x.shape[1])\n",
    "\n",
    "    # Scatter node features into hyperedge slots and sum them\n",
    "    hyperedge_feats.scatter_reduce_(\n",
    "        dim=0, \n",
    "        index=hyperedge_idx.unsqueeze(-1).expand(-1, x.shape[1]), \n",
    "        src=x[node_idx], \n",
    "        reduce=\"sum\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "fc37b19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 3]) tensor([1.0591, 0.4294, 0.8407])\n"
     ]
    }
   ],
   "source": [
    "edge_finding = __hyperedge_finding__(x, edge_list, 2, 3)\n",
    "print(edge_finding.shape, edge_finding[0, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5fee9057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2000, 3]) tensor([1.0591, 0.4294, 0.8407])\n"
     ]
    }
   ],
   "source": [
    "model = ModuleHyperEdgeFinding()\n",
    "model.eval()\n",
    "results = model(x, edge_list)\n",
    "print(results.shape, results[0, :3])\n",
    "\n",
    "# export to onnx\n",
    "model = torch.jit.script(model)\n",
    "torch.onnx.export(model, (x, edge_list, 2, 3), \"hyperedge_finding.onnx\", opset_version=18, dynamo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f80524cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0131 11:49:53.206000 72441 site-packages/torch/onnx/_internal/exporter/_registration.py:66] torchvision is not installed. Skipping torchvision::nms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[torch.onnx] Obtain model graph for `ModuleHyperEdgeFinding()` with `torch.export.export(..., strict=False)`...\n",
      "[torch.onnx] Obtain model graph for `ModuleHyperEdgeFinding()` with `torch.export.export(..., strict=False)`... ✅\n",
      "[torch.onnx] Run decomposition...\n",
      "[torch.onnx] Run decomposition... ✅\n",
      "[torch.onnx] Translate the graph into ONNX...\n",
      "[torch.onnx] Translate the graph into ONNX... ✅\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ONNXProgram(\n",
       "    model=\n",
       "        <\n",
       "            ir_version=10,\n",
       "            opset_imports={'pkg.onnxscript.torch_lib.common': 1, '': 18, 'pkg.onnxscript.torch_lib': 1},\n",
       "            producer_name='pytorch',\n",
       "            producer_version='2.6.0',\n",
       "            domain=None,\n",
       "            model_version=None,\n",
       "        >\n",
       "        graph(\n",
       "            name=main_graph,\n",
       "            inputs=(\n",
       "                %\"x\"<FLOAT,[100,3]>,\n",
       "                %\"hyperedge_index\"<INT64,[2,2000]>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"sum_1\"<FLOAT,[2000,3]>\n",
       "            ),\n",
       "        ) {\n",
       "             0 |  # node_Transpose_0\n",
       "                  %\"permute\"<INT64,[2000,2]> ⬅️ ::Transpose(%\"hyperedge_index\") {perm=[1, 0]}\n",
       "             1 |  # node_aten_unsqueeze_1\n",
       "                  %\"unsqueeze\"<FLOAT,[100,1,3]> ⬅️ pkg.onnxscript.torch_lib::aten_unsqueeze(%\"x\") {dim=1}\n",
       "             2 |  # node_Constant_2\n",
       "                  %\"val_0\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[3]>(array([-1,  2, -1]), name=None)}\n",
       "             3 |  # node_aten_expand_3\n",
       "                  %\"expand\"<FLOAT,[100,2,3]> ⬅️ pkg.onnxscript.torch_lib::aten_expand(%\"unsqueeze\", %\"val_0\")\n",
       "             4 |  # node_aten_unsqueeze_4\n",
       "                  %\"unsqueeze_1\"<INT64,[2000,2,1]> ⬅️ pkg.onnxscript.torch_lib::aten_unsqueeze(%\"permute\") {dim=2}\n",
       "             5 |  # node_Constant_5\n",
       "                  %\"val_1\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[3]>(array([-1, -1,  3]), name=None)}\n",
       "             6 |  # node_aten_expand_6\n",
       "                  %\"expand_1\"<INT64,[2000,2,3]> ⬅️ pkg.onnxscript.torch_lib::aten_expand(%\"unsqueeze_1\", %\"val_1\")\n",
       "             7 |  # node_Size_7\n",
       "                  %\"val_2\"<?,?> ⬅️ ::Size(%\"expand_1\")\n",
       "             8 |  # node_Cast_8\n",
       "                  %\"val_3\"<?,?> ⬅️ ::Cast(%\"expand_1\") {to=INT64}\n",
       "             9 |  # node_GatherElements_9\n",
       "                  %\"gather\"<FLOAT,[2000,2,3]> ⬅️ ::GatherElements(%\"expand\", %\"val_3\") {axis=0}\n",
       "            10 |  # node_Transpose_10\n",
       "                  %\"transpose\"<FLOAT,[2000,3,2]> ⬅️ ::Transpose(%\"gather\") {perm=[0, 2, 1]}\n",
       "            11 |  # node_Constant_11\n",
       "                  %\"val_4\"<?,?> ⬅️ ::Constant() {value_ints=[-1]}\n",
       "            12 |  # node_Constant_12\n",
       "                  %\"val_5\"<?,?> ⬅️ ::Constant() {value=Tensor<INT64,[1]>(array([2]), name=None)}\n",
       "            13 |  # node_Reshape_13\n",
       "                  %\"val_6\"<?,?> ⬅️ ::Reshape(%\"val_5\", %\"val_4\") {allowzero=0}\n",
       "            14 |  # node_Cast_14\n",
       "                  %\"val_7\"<?,?> ⬅️ ::Cast(%\"val_6\") {to=INT64}\n",
       "            15 |  # node_ReduceSum_15\n",
       "                  %\"sum_1\"<FLOAT,[2000,3]> ⬅️ ::ReduceSum(%\"transpose\", %\"val_7\") {keepdims=False, noop_with_empty_axes=0}\n",
       "            return %\"sum_1\"<FLOAT,[2000,3]>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::aten_unsqueeze(\n",
       "            inputs=(\n",
       "                %\"self\"<?,?>\n",
       "            ),\n",
       "            attributes={\n",
       "                dim: UNDEFINED\n",
       "            }\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"dim\"<?,?> ⬅️ ::Constant() {value_int=RefAttr('value_int', INT, ref_attr_name='dim')}\n",
       "            1 |  # n1\n",
       "                 %\"dim_0\"<?,?> ⬅️ ::Cast(%\"dim\") {to=7}\n",
       "            2 |  # n2\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Unsqueeze(%\"self\", %\"dim_0\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib::aten_expand(\n",
       "            inputs=(\n",
       "                %\"self\"<?,?>,\n",
       "                %\"size\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"size_0\"<?,?> ⬅️ ::Cast(%\"size\") {to=7}\n",
       "            1 |  # n1\n",
       "                 %\"size_1\"<?,?> ⬅️ ::Abs(%\"size_0\")\n",
       "            2 |  # n2\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Expand(%\"self\", %\"size_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::Rank(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "\n",
       "        <\n",
       "            opset_imports={'': 18},\n",
       "        >\n",
       "        def pkg.onnxscript.torch_lib.common::IsScalar(\n",
       "            inputs=(\n",
       "                %\"input\"<?,?>\n",
       "            ),\n",
       "            outputs=(\n",
       "                %\"return_val\"<?,?>\n",
       "            ),\n",
       "        ) {\n",
       "            0 |  # n0\n",
       "                 %\"tmp\"<?,?> ⬅️ ::Shape(%\"input\")\n",
       "            1 |  # n1\n",
       "                 %\"tmp_0\"<?,?> ⬅️ ::Size(%\"tmp\")\n",
       "            2 |  # n2\n",
       "                 %\"tmp_1\"<?,?> ⬅️ ::Constant() {value_int=0}\n",
       "            3 |  # n3\n",
       "                 %\"return_val\"<?,?> ⬅️ ::Equal(%\"tmp_0\", %\"tmp_1\")\n",
       "            return %\"return_val\"<?,?>\n",
       "        }\n",
       "    ,\n",
       "    exported_program=\n",
       "        ExportedProgram:\n",
       "            class GraphModule(torch.nn.Module):\n",
       "                def forward(self, x: \"f32[100, 3]\", hyperedge_index: \"i64[2, 2000]\", r, message_feats):\n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:3 in forward, code: hyperedge_index = hyperedge_index.permute(dims=(1,0))\n",
       "                    permute: \"i64[2000, 2]\" = torch.ops.aten.permute.default(hyperedge_index, [1, 0]);  hyperedge_index = None\n",
       "            \n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:5 in forward, code: x.unsqueeze(1).expand([-1,r,-1]),\n",
       "                    unsqueeze: \"f32[100, 1, 3]\" = torch.ops.aten.unsqueeze.default(x, 1);  x = None\n",
       "                    expand: \"f32[100, 2, 3]\" = torch.ops.aten.expand.default(unsqueeze, [-1, 2, -1]);  unsqueeze = None\n",
       "            \n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:7 in forward, code: hyperedge_index.unsqueeze(2).expand([-1, -1, message_feats])\n",
       "                    unsqueeze_1: \"i64[2000, 2, 1]\" = torch.ops.aten.unsqueeze.default(permute, 2);  permute = None\n",
       "                    expand_1: \"i64[2000, 2, 3]\" = torch.ops.aten.expand.default(unsqueeze_1, [-1, -1, 3]);  unsqueeze_1 = None\n",
       "            \n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:4 in forward, code: x_hyper = torch.gather(\n",
       "                    gather: \"f32[2000, 2, 3]\" = torch.ops.aten.gather.default(expand, 0, expand_1);  expand = expand_1 = None\n",
       "            \n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:8 in forward, code: ).transpose(1,2)\n",
       "                    transpose: \"f32[2000, 3, 2]\" = torch.ops.aten.transpose.int(gather, 1, 2);  gather = None\n",
       "            \n",
       "                     # File: /var/folders/v_/rpz3sncx2fg57t_m4n2_hkz40000gn/T/ipykernel_72441/2032141797.py:9 in forward, code: return x_hyper.sum(2)\n",
       "                    sum_1: \"f32[2000, 3]\" = torch.ops.aten.sum.dim_IntList(transpose, [2]);  transpose = None\n",
       "                    return (sum_1,)\n",
       "            \n",
       "        Graph signature: ExportGraphSignature(input_specs=[InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='x'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=TensorArgument(name='hyperedge_index'), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=ConstantArgument(name='r', value=2), target=None, persistent=None), InputSpec(kind=<InputKind.USER_INPUT: 1>, arg=ConstantArgument(name='message_feats', value=3), target=None, persistent=None)], output_specs=[OutputSpec(kind=<OutputKind.USER_OUTPUT: 1>, arg=TensorArgument(name='sum_1'), target=None)])\n",
       "        Range constraints: {}\n",
       "\n",
       ")"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# export to onnx with dynamo\n",
    "model = ModuleHyperEdgeFinding()\n",
    "model.eval()\n",
    "torch.onnx.export(model, (x, edge_list, 2, 3), \"hyperedge_finding_dynamo.onnx\", opset_version=18, dynamo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e02f19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterbook",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
